{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import os \n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor ,ProcessPoolExecutor,as_completed\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "cwd = os.getcwd()\n",
    "# Construct the full path to the 'FPL' directory\n",
    "fpl_path = os.path.join(cwd, '..', '..', 'FPL')\n",
    "# Add it to the system path\n",
    "sys.path.append(fpl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpl_api_collection import (\n",
    "    get_bootstrap_data,\n",
    "    get_current_gw,\n",
    "    get_fixt_dfs,\n",
    "    get_fixture_data,\n",
    "    get_player_id_dict,\n",
    "    get_current_season,\n",
    "    get_player_data,\n",
    "    remove_moved_players\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and prepare player data\n",
    "ele_types_data = get_bootstrap_data()['element_types']\n",
    "ele_types_df = pd.DataFrame(ele_types_data)\n",
    "ele_data = get_bootstrap_data()['elements']\n",
    "ele_df = pd.DataFrame(ele_data)\n",
    "ele_df['element_type'] = ele_df['element_type'].map(ele_types_df.set_index('id')['singular_name_short'])\n",
    "ele_df['logo_player'] = \"https://resources.premierleague.com/premierleague/photos/players/250x250/p\" + ele_df['code'].astype(str) + \".png\"\n",
    "ele_copy = ele_df.copy()\n",
    "\n",
    "# Retrieve and prepare team data\n",
    "teams_data = get_bootstrap_data()['teams']\n",
    "teams_df = pd.DataFrame(teams_data)\n",
    "teams_df['logo_url'] = \"https://resources.premierleague.com/premierleague/badges/70/t\" + teams_df['code'].astype(str) + \".png\"\n",
    "\n",
    "# Map team IDs to names for fixture processing\n",
    "team_name_mapping = pd.Series(teams_df.name.values, index=teams_df.id).to_dict()\n",
    "ele_copy['team_name'] = ele_copy['team'].map(teams_df.set_index('id')['short_name'])\n",
    "ele_copy['full_name'] = ele_copy['first_name'].str.cat(ele_copy['second_name'].str.cat(ele_copy['team_name'].apply(lambda x: f\" ({x})\"), sep=''), sep=' ')\n",
    "\n",
    "# Retrieve player dictionary and current season/gameweek\n",
    "full_player_dict = get_player_id_dict('total_points', web_name=False)\n",
    "crnt_season = get_current_season()\n",
    "ct_gw = get_current_gw()\n",
    "\n",
    "# Retrieve and process fixture data\n",
    "fixture_data = get_fixture_data()\n",
    "fixtures_df = pd.DataFrame(fixture_data)\n",
    "fixtures_df.drop(columns='stats', inplace=True)\n",
    "fixtures_df = fixtures_df.merge(teams_df[['id', 'logo_url']], left_on='team_h', right_on='id', how='left').rename(columns={'logo_url': 'team_h_logo'})\n",
    "fixtures_df = fixtures_df.merge(teams_df[['id', 'logo_url']], left_on='team_a', right_on='id', how='left').rename(columns={'logo_url': 'team_a_logo'})\n",
    "fixtures_df['team_h'] = fixtures_df['team_h'].replace(team_name_mapping)\n",
    "fixtures_df['team_a'] = fixtures_df['team_a'].replace(team_name_mapping)\n",
    "fixtures_df = fixtures_df.drop(columns=['pulse_id'])\n",
    "\n",
    "# Format fixture dates\n",
    "timezone = 'Europe/London'\n",
    "fixtures_df['datetime'] = pd.to_datetime(fixtures_df['kickoff_time'], utc=True)\n",
    "fixtures_df['local_time'] = fixtures_df['datetime'].dt.tz_convert(timezone).dt.strftime('%A %d %B %Y %H:%M')\n",
    "fixtures_df['local_date'] = fixtures_df['datetime'].dt.tz_convert(timezone).dt.strftime('%d %A %B %Y')\n",
    "fixtures_df['local_hour'] = fixtures_df['datetime'].dt.tz_convert(timezone).dt.strftime('%H:%M')\n",
    "\n",
    "# Retrieve fixture difficulty rating data\n",
    "team_fdr_df, team_fixt_df, team_ga_df, team_gf_df = get_fixt_dfs()\n",
    "full_player_dict = get_player_id_dict('total_points', web_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_score_to_result(df):\n",
    "    df.loc[df['was_home'] == True, 'result'] = df['team_h_score'] \\\n",
    "        .astype('Int64').astype(str) \\\n",
    "        + '-' + df['team_a_score'].astype('Int64').astype(str)\n",
    "    df.loc[df['was_home'] == False, 'result'] = df['team_a_score'] \\\n",
    "        .astype('Int64').astype(str) \\\n",
    "        + '-' + df['team_h_score'].astype('Int64').astype(str)\n",
    "        \n",
    "def convert_opponent_string(df):\n",
    "    df.loc[df['was_home'] == True, 'vs'] = df['vs'] + ' (A)'\n",
    "    df.loc[df['was_home'] == False, 'vs'] = df['vs'] + ' (H)'\n",
    "    df.loc[df['was_home'] == True, 'Team_player'] = df['Team_player'] + ' (H)'\n",
    "    df.loc[df['was_home'] == False, 'Team_player'] = df['Team_player'] + ' (A)'\n",
    "    return df\n",
    "\n",
    "def collate_hist_df_from_name(player_name):\n",
    "    p_id = [k for k, v in full_player_dict.items() if v == player_name]\n",
    "    position = ele_copy.loc[ele_copy['full_name'] == player_name, 'element_type'].iloc[0]\n",
    "    Team = ele_copy.loc[ele_copy['full_name'] == player_name, 'team_name'].iloc[0]\n",
    "    p_data = get_player_data(str(p_id[0]))\n",
    "    p_df = pd.DataFrame(p_data['history'])\n",
    "    convert_score_to_result(p_df)\n",
    "    p_df.loc[p_df['result'] == '<NA>-<NA>', 'result'] = '-'\n",
    "    rn_dict = {'round': 'GW','kickoff_time':'kickoff_time', 'opponent_team': 'vs', 'total_points': 'Pts',\n",
    "               'minutes': 'Mins', 'goals_scored': 'GS', 'assists': 'A',\n",
    "               'clean_sheets': 'CS', 'goals_conceded': 'GC', 'own_goals': 'OG',\n",
    "               'penalties_saved': 'Pen_Save', 'penalties_missed': 'Pen_Miss',\n",
    "               'yellow_cards': 'YC', 'red_cards': 'RC', 'saves': 'S',\n",
    "               'bonus': 'B', 'bps': 'BPS', 'influence': 'I', 'creativity': 'C',\n",
    "               'threat': 'T', 'ict_index': 'ICT', 'value': 'Price',\n",
    "               'selected': 'SB', 'transfers_in': 'Tran_In',\n",
    "               'transfers_out': 'Tran_Out', 'expected_goals': 'xG',\n",
    "               'expected_assists': 'xA', 'expected_goal_involvements': 'xGI',\n",
    "               'expected_goals_conceded': 'xGC', 'result': 'Result'}\n",
    "    p_df.rename(columns=rn_dict, inplace=True)\n",
    "    col_order = ['GW','kickoff_time', 'vs', 'Result', 'Pts', 'Mins', 'GS', 'xG', 'A', 'xA',\n",
    "                 'xGI', 'Pen_Miss', 'CS', 'GC', 'xGC', 'OG', 'Pen_Save', 'S',\n",
    "                 'YC', 'RC', 'B', 'BPS', 'Price', 'I', 'C', 'T', 'ICT', 'SB',\n",
    "                 'Tran_In', 'Tran_Out', 'was_home']\n",
    "    p_df = p_df[col_order]\n",
    "    # map opponent teams\n",
    "    \n",
    "    p_df['Price'] = p_df['Price']/10\n",
    "    p_df['vs'] = p_df['vs'].map(teams_df.set_index('id')['short_name'])\n",
    "    p_df['Pos'] = position\n",
    "    p_df['Team_player'] = Team\n",
    "    #convert_opponent_string(p_df)\n",
    "    #p_df.drop('was_home', axis=1, inplace=True)\n",
    "    #p_df.set_index('GW', inplace=True)\n",
    "    p_df.sort_values('GW', ascending=False, inplace=True)\n",
    "    return p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_all_players_parallel(full_player_dict, max_workers=None):\n",
    "    # Determine optimal max_workers if not provided\n",
    "    if max_workers is None:\n",
    "        max_workers = os.cpu_count() * 2  # Suitable for I/O-bound tasks like web scraping\n",
    "\n",
    "    # Define a helper function to retrieve data for a single player\n",
    "    def get_player_data(player_name):\n",
    "        try:  # Add exception handling inside the worker function\n",
    "            player_df = collate_hist_df_from_name(player_name)\n",
    "            player_df['Player'] = player_name  # Add player name column\n",
    "            return player_df\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {player_name}: {e}\")\n",
    "            return pd.DataFrame() # Return empty DataFrame on error\n",
    "\n",
    "\n",
    "    # Use ThreadPoolExecutor with a with statement for proper resource management\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit tasks and store futures in a dictionary for easier error handling\n",
    "        futures = {executor.submit(get_player_data, player_name): player_name \n",
    "                   for player_name in full_player_dict.values()}\n",
    "\n",
    "        results = []\n",
    "        for future in as_completed(futures):\n",
    "            player_name = futures[future]\n",
    "            try:\n",
    "                result_df = future.result()  # Get the result or raise an exception\n",
    "                results.append(result_df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error retrieving result for {player_name}: {e}\")\n",
    "\n",
    "    # Concatenate all successful results into a single DataFrame outside the loop\n",
    "    all_players_df = pd.concat(results, axis=0, ignore_index=True)  # ignore_index for cleaner index\n",
    "    return all_players_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_players_data = collate_all_players_parallel(full_player_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_players_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_home = pd.merge(all_players_data, teams_df[['short_name',\n",
    "                                                    'strength_overall_home', \n",
    "                                                    'strength_overall_away', \n",
    "                                                    'strength_attack_home', \n",
    "                                                    'strength_attack_away', \n",
    "                                                    'strength_defence_home', \n",
    "                                                    'strength_defence_away']],\n",
    "                       left_on='Team_player', \n",
    "                       right_on='short_name', \n",
    "                       how='left')\n",
    "\n",
    "# Merge for the opponent team\n",
    "merged_opponent = pd.merge(merged_home, \n",
    "                            teams_df[['short_name',\n",
    "                                       'strength_overall_home', \n",
    "                                       'strength_overall_away', \n",
    "                                       'strength_attack_home', \n",
    "                                       'strength_attack_away', \n",
    "                                       'strength_defence_home', \n",
    "                                       'strength_defence_away']],\n",
    "                            left_on='vs', \n",
    "                            right_on='short_name', \n",
    "                            how='left', \n",
    "                            suffixes=('', '_opponent'))\n",
    "\n",
    "# Optionally drop the 'short_name' columns for opponents if you don't need them\n",
    "merged_opponent = merged_opponent.drop(columns=['short_name', 'short_name_opponent'])\n",
    "merged_opponent=convert_opponent_string(merged_opponent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_opponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_fdr_df, team_fixt_df, team_ga_df, team_gf_df = get_fixt_dfs()\n",
    "\n",
    "ct_gw = get_current_gw()\n",
    "\n",
    "new_fixt_df = team_fixt_df.loc[:, ct_gw:(ct_gw+2)]\n",
    "new_fixt_cols = ['GW' + str(col) for col in new_fixt_df.columns.tolist()]\n",
    "new_fixt_df.columns = new_fixt_cols\n",
    "\n",
    "new_fdr_df = team_fdr_df.loc[:, ct_gw:(ct_gw+2)]\n",
    "\n",
    "def get_home_away_str_dict():\n",
    "    new_fdr_df.columns = new_fixt_cols\n",
    "    result_dict = {}\n",
    "    for col in new_fdr_df.columns:\n",
    "        values = list(new_fdr_df[col])\n",
    "        max_length = new_fixt_df[col].str.len().max()\n",
    "        if max_length > 7:\n",
    "            new_fixt_df.loc[new_fixt_df[col].str.len() <= 7, col] = new_fixt_df[col].str.pad(width=max_length+9, side='both', fillchar=' ')\n",
    "        strings = list(new_fixt_df[col])\n",
    "        value_dict = {}\n",
    "        for value, string in zip(values, strings):\n",
    "            if value not in value_dict:\n",
    "                value_dict[value] = []\n",
    "            value_dict[value].append(string)\n",
    "        result_dict[col] = value_dict\n",
    "    \n",
    "    merged_dict = {}\n",
    "    for k, dict1 in result_dict.items():\n",
    "        for key, value in dict1.items():\n",
    "            if key in merged_dict:\n",
    "                merged_dict[key].extend(value)\n",
    "            else:\n",
    "                merged_dict[key] = value\n",
    "    for k, v in merged_dict.items():\n",
    "        decoupled_list = list(set(v))\n",
    "        merged_dict[k] = decoupled_list\n",
    "    for i in range(1,6):\n",
    "        if i not in merged_dict:\n",
    "            merged_dict[i] = []\n",
    "    return merged_dict\n",
    "\t\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sui=get_home_away_str_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_fdr_df, team_fixt_df, team_ga_df, team_gf_df = get_fixt_dfs()\n",
    "\n",
    "ct_gw = get_current_gw()\n",
    "\n",
    "new_fixt_df = team_fixt_df.loc[:, ct_gw:(ct_gw+2)]\n",
    "new_fixt_cols = ['GW' + str(col) for col in new_fixt_df.columns.tolist()]\n",
    "new_fixt_df.columns = new_fixt_cols\n",
    "\n",
    "def create_team_fdr_dataframe():\n",
    "\n",
    "\n",
    "    # Create a list to store the results\n",
    "    team_fdr_list = []\n",
    "\n",
    "    for col in new_fdr_df.columns:\n",
    "        # Get the values from the FDR DataFrame\n",
    "        fdr_values = new_fdr_df[col].values\n",
    "        # Get the corresponding teams from the fixture DataFrame\n",
    "        teams = new_fixt_df[col].values\n",
    "        \n",
    "        # Combine teams with their FDR values into the list\n",
    "        for team, fdr in zip(teams, fdr_values):\n",
    "            # Ensure that we don't include empty FDR values or teams\n",
    "            if pd.notna(fdr) and fdr > 0:  # Adjust condition as needed\n",
    "                team_fdr_list.append({'team': team.strip(), 'fdr': fdr})\n",
    "\n",
    "    # Create a DataFrame from the list\n",
    "    team_fdr_df = pd.DataFrame(team_fdr_list)\n",
    "\n",
    "    return team_fdr_df\n",
    "\n",
    "# Example usage\n",
    "team_fdr_df = create_team_fdr_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_fdr_map = dict(zip(team_fdr_df['team'], team_fdr_df['fdr']))\n",
    "\n",
    "# Map the 'fdr' values to the 'merged_opponent' dataframe based on the 'Team_player' column\n",
    "merged_opponent['Team_fdr'] = merged_opponent['Team_player'].map(team_fdr_map)\n",
    "merged_opponent['opponent_fdr'] = merged_opponent['vs'].map(team_fdr_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = ['GW', 'Pts', 'Mins', 'GS', 'xG', 'A', 'xA', 'xGI', 'Pen_Miss', \n",
    "                      'CS', 'GC', 'xGC', 'OG', 'Pen_Save', 'S', 'YC', 'RC', 'B', 'BPS', \n",
    "                      'Price', 'I', 'C', 'T', 'ICT', 'SB', 'Tran_In', 'Tran_Out', \n",
    "                      'strength_overall_home', 'strength_overall_away', 'strength_attack_home', 'strength_attack_away', \n",
    "                      'strength_defence_home', 'strength_defence_away', 'strength_overall_home_opponent', \n",
    "                      'strength_overall_away_opponent', 'strength_attack_home_opponent', 'strength_attack_away_opponent', \n",
    "                      'strength_defence_home_opponent', 'strength_defence_away_opponent', 'Team_fdr', 'opponent_fdr']\n",
    "\n",
    "\n",
    "# Convert specified columns to float\n",
    "for col in columns_to_convert:\n",
    "    merged_opponent[col] = pd.to_numeric(merged_opponent[col], errors='coerce')  # Convert to float and set errors to NaN if conversion fails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_opponent['season']=2425"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####FIXTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_fixture_gw = fixtures_df[fixtures_df['event']==ct_gw]\n",
    "next_fixture_gw.drop(['team_h_logo', 'team_a_logo'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge for team_a\n",
    "new_fix_gw_a = pd.merge(\n",
    "    next_fixture_gw,\n",
    "    teams_df[['short_name', 'name']],  # Include 'name' for matching\n",
    "    left_on='team_a',  # Match with team_a\n",
    "    right_on='name', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Rename the short_name column for clarity\n",
    "new_fix_gw_a.rename(columns={'short_name': 'team_a_short_name'}, inplace=True)\n",
    "\n",
    "# Merge for team_h\n",
    "new_fix_gw = pd.merge(\n",
    "    new_fix_gw_a,\n",
    "    teams_df[['short_name', 'name']],  # Include 'name' for matching\n",
    "    left_on='team_h',  # Match with team_h\n",
    "    right_on='name', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Rename the short_name column for clarity\n",
    "new_fix_gw.rename(columns={'short_name': 'team_h_short_name'}, inplace=True)\n",
    "new_fix_gw = new_fix_gw.drop(columns=['name_x', 'name_y'], errors='ignore')\n",
    "new_fix_gw['team_h_short_name'] = new_fix_gw['team_h_short_name'] + ' (H)'\n",
    "new_fix_gw['team_a_short_name'] = new_fix_gw['team_a_short_name'] + ' (A)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_next_gw = pd.concat([new_fix_gw['team_a_short_name'], new_fix_gw['team_h_short_name']]).unique()\n",
    "filtered_players = merged_opponent\n",
    "\n",
    "filtered_players[['team_player_score', 'vs_score']] = filtered_players['Result'].str.split('-', expand=True)\n",
    "\n",
    "# Convert the scores to integers (optional, depending on how you want to use them)\n",
    "filtered_players['team_player_score'] = filtered_players['team_player_score'].astype(int)\n",
    "filtered_players['vs_score'] = filtered_players['vs_score'].astype(int)\n",
    "filtered_players.drop(columns=['Result'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fix_gw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fix_gw_test = new_fix_gw[['event', 'team_h_short_name', 'team_a_short_name','kickoff_time']].rename(\n",
    "    columns={\n",
    "        'event': 'GW',\n",
    "        'team_h_short_name': 'Team_home',\n",
    "        'team_a_short_name': 'Team_away',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fix_gw_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_path= os.path.join(cwd, '..', '..', 'data', 'history', 'clean_player_2324.csv')\n",
    "\n",
    "player_history = pd.read_csv(history_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the dataframes vertically\n",
    "concatenated_df = pd.concat([filtered_players, player_history], ignore_index=True)\n",
    "\n",
    "# If you want to reset the index after concatenation\n",
    "concatenated_df.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fix_gw_test['season']=2425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate the average statistics for each team from df_player\n",
    "df_player=concatenated_df\n",
    "df_fixture=new_fix_gw_test\n",
    "\n",
    "\n",
    "filtered_players_fixture = df_player[\n",
    "    (df_player['Team_player'].isin(teams_next_gw)) & \n",
    "    (df_player['season'] == 2425)\n",
    "]# 5. Add additional statistics for home and away teams (team strength, FDR, and price from df_player)\n",
    "df_fixture_home = pd.merge(\n",
    "    df_fixture,\n",
    "    filtered_players_fixture[['Team_player', 'Player', 'was_home', 'Pos', 'Price']],\n",
    "    left_on='Team_home',\n",
    "    right_on='Team_player',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_fixture_away = pd.merge(\n",
    "    df_fixture,\n",
    "    filtered_players_fixture[['Team_player', 'Player', 'was_home', 'Pos', 'Price']],\n",
    "    left_on='Team_away',\n",
    "    right_on='Team_player',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "\n",
    "df_fixture_full = pd.concat([df_fixture_home, df_fixture_away], axis=0, ignore_index=True)\n",
    "\n",
    "total_stats =filtered_players_fixture.groupby('Player')[['Pts', 'Mins', 'GS', 'xG', 'A', 'xA', 'xGI', 'Pen_Miss', 'CS', 'GC', \n",
    "                                           'xGC', 'OG', 'Pen_Save', 'S', 'YC', 'RC', 'B', 'BPS', 'I', 'C', 'T', \n",
    "                                           'ICT', 'SB', 'Tran_In', 'Tran_Out']].mean().reset_index()\n",
    "\n",
    "\"\"\"\n",
    "for col in total_stats.columns[2:]:  # Skip 'Player' and 'Mins'\n",
    "    total_stats[col] = total_stats[col] / (total_stats['Mins'] / 90)\n",
    "\"\"\"\n",
    "\n",
    "# 2. Merge df_fixture with df_player based on Team_home (home team stats)\n",
    "df_pred = pd.merge(df_fixture_full, total_stats,\n",
    "                           left_on='Player', right_on='Player', how='left')\n",
    "\n",
    "\n",
    "df_pred['vs'] = df_pred.apply(\n",
    "    lambda row: row['Team_away'] if row['Team_player'] == row['Team_home'] else row['Team_home'] if row['Team_player'] == row['Team_away'] else None, axis=1\n",
    ")\n",
    "\n",
    "# Drop the columns as per the condition\n",
    "df_pred = df_pred.drop(columns=['Team_home', 'Team_away'])\n",
    "\n",
    "df_pred['vs_temp'] = df_pred['vs'].str.replace(r'\\s?\\(.*\\)', '', regex=True)\n",
    "df_pred['Team_player_temp'] = df_pred['Team_player'].str.replace(r'\\s?\\(.*\\)', '', regex=True)\n",
    "\n",
    "\n",
    "pred_home = pd.merge(df_pred, teams_df[['short_name', \n",
    "                                                    'strength_overall_home', \n",
    "                                                    'strength_overall_away', \n",
    "                                                    'strength_attack_home', \n",
    "                                                    'strength_attack_away', \n",
    "                                                    'strength_defence_home', \n",
    "                                                    'strength_defence_away']],\n",
    "                       left_on='Team_player_temp', \n",
    "                       right_on='short_name', \n",
    "                       how='left')\n",
    "\n",
    "# Merge for the opponent team\n",
    "pred_opponent = pd.merge(pred_home, \n",
    "                            teams_df[['short_name', \n",
    "                                       'strength_overall_home', \n",
    "                                       'strength_overall_away', \n",
    "                                       'strength_attack_home', \n",
    "                                       'strength_attack_away', \n",
    "                                       'strength_defence_home', \n",
    "                                       'strength_defence_away']],\n",
    "                            left_on='vs_temp', \n",
    "                            right_on='short_name', \n",
    "                            how='left', \n",
    "                            suffixes=('', '_opponent'))\n",
    "\n",
    "# Optionally drop the 'short_name' columns for opponents if you don't need them\n",
    "df_next_fixt = pred_opponent.drop(columns=['short_name', 'short_name_opponent','vs_temp','Team_player_temp'])\n",
    "\n",
    "\n",
    "merged_fdr_home = pd.merge(\n",
    "    df_next_fixt, \n",
    "    team_fdr_df[['team', 'fdr']], \n",
    "    left_on='Team_player',  # Assuming 'Team_home' in df_next_fixt, replace with 'Team_player' if necessary\n",
    "    right_on='team', \n",
    "    how='left'\n",
    ").rename(columns={'fdr': 'Team_fdr'}).drop_duplicates(subset=['Player'])\n",
    "\n",
    "# Merge FDR data for away teams using the merged_fdr_home result\n",
    "merged_fdr_away = pd.merge(\n",
    "    merged_fdr_home, \n",
    "    team_fdr_df[['team', 'fdr']], \n",
    "    left_on='Team_player',  # Assuming 'Team_away' in df_next_fixt\n",
    "    right_on='team', \n",
    "    how='left'\n",
    ").rename(columns={'fdr': 'opponent_fdr'}).drop_duplicates(subset=['Player'])\n",
    "# Drop the extra 'team' columns from the final merged dataframe\n",
    "df_next_fixt_gw = merged_fdr_away.drop(columns=['team_x', 'team_y'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to convert to float\n",
    "columns_to_convert = [\n",
    "    'GW', 'Pts', 'Mins', 'GS', 'xG', 'A', 'xA', 'xGI', 'Pen_Miss', 'CS', 'GC',\n",
    "    'xGC', 'OG', 'Pen_Save', 'S', 'YC', 'RC', 'B', 'BPS', 'Price', 'I', 'C',\n",
    "    'T', 'ICT', 'SB', 'Tran_In', 'Tran_Out', 'strength_overall_home',\n",
    "    'strength_overall_away', 'strength_attack_home', 'strength_attack_away',\n",
    "    'strength_defence_home', 'strength_defence_away',\n",
    "    'strength_overall_home_opponent', 'strength_overall_away_opponent',\n",
    "    'strength_attack_home_opponent', 'strength_attack_away_opponent',\n",
    "    'strength_defence_home_opponent', 'strength_defence_away_opponent',\n",
    "    'Team_fdr', 'opponent_fdr'\n",
    "]\n",
    "\n",
    "df_next_fixt_gw[columns_to_convert] = df_next_fixt_gw[columns_to_convert].astype(float)\n",
    "df_player[columns_to_convert] = df_player[columns_to_convert].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_player.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weights = {\n",
    "    'GKP': {\n",
    "        'CS': 1.5,    # Clean sheets more important for goalkeepers\n",
    "        'Pen_Save': 1.3,\n",
    "        'S': 1.2\n",
    "    },\n",
    "    'DEF': {\n",
    "        'CS': 1.4,\n",
    "        'B': 1.3,     # Bonus points\n",
    "        'xGC': 1.2    # Expected goals conceded\n",
    "    },\n",
    "    'MID': {\n",
    "        'GS': 1.3,    # Goals scored\n",
    "        'A': 1.4,     # Assists\n",
    "        'xA': 1.2\n",
    "    },\n",
    "    'FWD': {\n",
    "        'GS': 1.5,\n",
    "        'xG': 1.3,\n",
    "        'S': 1.1      # Shots taken\n",
    "    }\n",
    "}\n",
    "home_away_weights = {\n",
    "    True: {  # Home game weights\n",
    "        'GS': 1.2,         # Goals scored\n",
    "        'xG': 1.1,         # Expected goals\n",
    "        'CS': 1.3,         # Clean sheets\n",
    "        'strength_attack_home': 1.1,\n",
    "        'strength_defence_home': 1.2\n",
    "    },\n",
    "    False: {  # Away game weights\n",
    "        'GS': 1.1,         # Goals scored\n",
    "        'xG': 1.0,\n",
    "        'CS': 1.1,\n",
    "        'strength_attack_away': 1.0,\n",
    "        'strength_defence_away': 1.1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of X to apply weights\n",
    "X_weighted = df_player.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ 'Mins', 'GS', 'xG', 'A', 'xA', 'xGI', 'Pen_Miss',\n",
    "       'CS', 'GC', 'xGC', 'OG', 'Pen_Save', 'S', 'YC', 'RC', 'B', 'BPS',\n",
    "       'Price', 'I', 'C', 'T', 'ICT', 'SB', 'Tran_In', 'Tran_Out', 'was_home','strength_overall_home',\n",
    "       'strength_overall_away', 'strength_attack_home', 'strength_attack_away',\n",
    "       'strength_defence_home', 'strength_defence_away',\n",
    "       'strength_overall_home_opponent', 'strength_overall_away_opponent',\n",
    "       'strength_attack_home_opponent', 'strength_attack_away_opponent',\n",
    "       'strength_defence_home_opponent', 'strength_defence_away_opponent','Team_fdr', 'opponent_fdr','season']\n",
    "X = X_weighted[features]\n",
    "y = df_player['Pts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Initialize the XGBoost regressor\n",
    "xgb_model = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    min_child_weight=3,\n",
    "    subsample= 0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    gamma=0.1,\n",
    "    alpha=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False  # Set to True if you want to see logs\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb.plot_importance(xgb_model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = xgb_model.get_booster().get_score(importance_type='weight')  # You can change to 'gain' or 'cover'\n",
    "importance_df = pd.DataFrame(importance.items(), columns=['Feature', 'Importance'])\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssuiio=df_next_fixt_gw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = ssuiio[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdazdazd=xgb_model.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssuiio['prediction']=azdazdazd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sort the dataframe by 'Pos' and 'prediction' to get the top 5 players per position\n",
    "top_players_per_pos = ssuiio.sort_values(by=['Pos', 'prediction'], ascending=[True, False])\n",
    "\n",
    "# Group by position and select the top 5 players\n",
    "top_5_players = top_players_per_pos.groupby('Pos').head(5)\n",
    "\n",
    "# Create a plot for the top 5 players per position\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=top_5_players, x='prediction', y='Player', hue='Pos', dodge=False)\n",
    "\n",
    "# Title and labels\n",
    "plt.title('Top 5 Players per Position Based on Prediction', fontsize=16)\n",
    "plt.xlabel('Prediction Value', fontsize=14)\n",
    "plt.ylabel('Player', fontsize=14)\n",
    "plt.legend(title='Position')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
